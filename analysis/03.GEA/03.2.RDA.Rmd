---
title: "RDA"
author: "Erica Robertson"
date: "2025-08-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir="~/Desktop/BANS/BANS_adaptive_units/")
```

```{r, label="packages"}
library(pegas)
library(ggplot2)
library(rnaturalearth)
library(rnaturalearthdata)
library(RColorBrewer)
library(ggpubr)
library(vegan)
library(robust)
library(ggVennDiagram)
library(cowplot)
library(corrplot)
library(data.table)
library(tidyverse)
library(qvalue) <----
library(adegenet)
library(dplyr)
```


# Reformatting vcf with PLINK
```{bash}
conda activate GWAS2
plink -vcf ../data/BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss.recode.vcf.gz --aec --recode A --out BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss
```

This generates the following files:
BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss.log
BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss.nosex
BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss.raw

With the recode A function 
-Each genotype is coded as 0, 1, or 2, representing the number of copies of the alternate (usually minor) allele an individual has at each SNP.
-Missing genotypes are typically coded as -1.

Recommended next step is to cut the header off the plink file before moving it into R, for downstream stuff to work.

```{bash}
cut -d$'\t' -f7- BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss.raw > BANS.ds6x.pass-maf-0.05.SNP.above4x.nomiss.raw_noheader.raw
```

# Loading data into R

Now we need to get the allele frequency and environmental data into R. This isn't going to run well on your local computer unless you only have a small subset of SNPs. A good way to do this is sample your vcf and move over a subset to test the scripts on your local machine, and then pop them back over to the cluster when they're ready to run on the full set.

```{bash, label="subsample_vcf"}
#making a LD pruned VCF to pull from
bfile="/scratch/alpine/ericacnr@colostate.edu/BANS/02.imputation/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1"
plink --bfile $bfile \
      --aec \
      --set-missing-var-ids @:# \
      --extract BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.vcf.gz.prune.in \
      --recode vcf \
      --out BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5

#check that SNPs have ID's
bcftools query -f '%ID' BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.vcf | head
#CM026847.30063 which is CHROM.POS
      
#subset the vcf
bcftools query -f '%ID\n' BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.vcf | grep '^CM' | shuf -n 10000 > snplist.txt

bgzip BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.vcf
tabix -p vcf BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.vcf.gz

bcftools view -i ID=@snplist.txt BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.vcf.gz -o subsampled.vcf

#rerun plink
conda activate GWAS2
plink --vcf subsampled.vcf --aec --make-bed --out subsampled
plink --bfile subsampled -aec --recode A --out subsampled

#recut header
cut -d$'\t' -f7- subsampled.raw > subsampled_noheader.raw
```

Alright, move that over to your local computer.

```{bash}
rsync -avzP ericacnr@colostate.edu@login.rc.colorado.edu:/scratch/alpine/ericacnr@colostate.edu/BANS/03.GEA/subsampled*.raw /Users/ericarobertson/Desktop/BANS_adaptive_units/data/
rsync -avzP ericacnr@colostate.edu@login.rc.colorado.edu:/scratch/alpine/ericacnr@colostate.edu/BANS/03.GEA/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.fam /Users/ericarobertson/Desktop/BANS_adaptive_units/data/
```

```{r}
pops <- read.table(file = "BANS_sample_list_pop.tsv", sep="\t", header = FALSE) %>% rename(BGP_ID = V1, Pop = V3) %>% dplyr::select(BGP_ID, Pop)

#all.freq <- fread("data/losh.33pop.frq.strat.50k_A.txt") ## instead of running on allele frequency per population, try running on individual genotypes...

genotypes <- fread("/Users/ericarobertson/Desktop/BANS_adaptive_units/data/subsampled_noheader.raw")

indorder <- fread("../../data/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.fam") %>% rename(BGP_ID = V1) %>% dplyr::select(BGP_ID)

env <- read_delim("../../data/spatial_files/BANS.initial.worldclim.txt", delim = "\t")

env <- left_join(indorder, env, by = "BGP_ID")

env$BGP_ID == indorder$BGP_ID

env %>% as.data.frame() %>% dplyr::select(-"BGP_ID", bio02, bio03, bio05, bio07) %>% write.table("../../data/BANS.climtop4.txt", row.names = F, quote = F, sep = "\t")

## read this in in the rda.R script
env2 <- fread("../../data/BANS.climtop4.txt", sep = "\t")
```

```{r}
# source("./src/rdadapt.R")
# rdadapt_env_unconstrained <- rdadapt(RDA_env_unconstrained, 2)
# thres_env <- 0.01/length(rdadapt_env_unconstrained$p.values)
# 
# 
# ## Identifying the outliers for the simple RDA
# outliers_unconstrained <- data.frame(Loci = colnames(all.freq)[which(rdadapt_env_unconstrained$p.values<thres_env)], p.value = rdadapt_env_unconstrained$p.values[which(rdadapt_env_unconstrained$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(all.freq)[which(rdadapt_env_unconstrained$p.values<thres_env)], split = "_"), function(x) x[1])))
# outliers_unconstrained <- outliers_unconstrained[order(outliers_unconstrained$contig, outliers_unconstrained$p.value),]
# outliers_rdadapt_env_unconstrained <- as.character(outliers_unconstrained$Loci[!duplicated(outliers_unconstrained$contig)])
```

# Population Structure
###plink pca
In this step we're making the population structure PCA to identify mems that can be used to control for population structure later when running the RDA. You want to do N-1 for your number of PC's, where N is the population size.
```{bash}
plink --bfile ../BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5 --pca 138 header --out BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5 --aec 
```
move the files over
```{bash}
rsync -avzP ericacnr@colostate.edu@login.rc.colorado.edu:/scratch/alpine/ericacnr@colostate.edu/BANS/03.GEA/pop_struc/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.* /Users/ericarobertson/Desktop/BANS_adaptive_units/analysis/03.GEA/pop_struc
```

```{r}
# load required libraries
library(adespatial) # for spatial eigenfunction analysis like dbMEM
library(sf) # for handling spatial features (coordinates, projections, etc.)
library(vegan) # for multivariate analysis (e.g., RDA, PCA, variable selection)
library(data.table)

indorder <- fread("../../data/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.fam") %>% rename(BGP_ID = V1) %>% dplyr::select(BGP_ID)

# read in plink pca
plink_pca <- read.table("pop_struc/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.eigenvec", header = TRUE)

# clean and rename: drop 'FID' and rename 'IID' to 'BGP_ID' to match other metadata
plink_pca <- plink_pca %>% dplyr::select(-FID) %>% rename(BGP_ID = IID)
```
### visualizing pop struc
Let's go through the plotting of the PCA to stay oriented. Then we can do the mems.

```{r}
library(tidyverse)
plink_pca <- read.table("pop_struc/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.eigenvec", header = TRUE)
eigenval <- scan("pop_struc/BANS.ds6x.maf.0.05.SNP.above4x.maxmiss.8.imputed4.1.ld25-10-0.5.eigenval")

# set names
pca05 <- plink_pca
names(pca05)[1] <- "ind"
nrow(pca05)
#correct number of samples

id.loc <- read.csv("../../data/BANS_sample_data.csv")

loc <- data.frame(as.factor(id.loc$BGP.ID), id.loc$Location)
colnames(loc) <- c("ind", "site")
pca05 <- left_join(pca05, loc, by="ind")
pca05$spp <- "BANS"
spp <- pca05$spp
pca05 <- pca05 %>% dplyr::select(spp, ind, site, everything())

# combine - if you want to plot each in different colours
spp_loc <- paste0("BANS", "_", pca05$site)

pca05 <- as_tibble(data.frame(pca05, spp_loc))
```
```{r}
pve05 <- data.frame(PC = 1:138, pve = eigenval/sum(eigenval)*100)

# make plot
a05 <- ggplot(pve05, aes(PC, pve)) + geom_bar(stat = "identity")
a05 + ylab("Percentage variance explained") + theme_light()

b05 <- ggplot(pca05, aes(PC1, PC2, col = site))+
  geom_point(size = 3)+
  scale_color_manual(values = scales::hue_pal()(15))+
  coord_equal() + theme_light()+
  xlab(paste0("PC1 (", signif(pve05$pve[1], 3), "%)")) + ylab(paste0("PC2 (", signif(pve05$pve[2], 3), "%)"))
b05
```

###clustering by geography
##Time to plot the PCA.
```{r}
library(ggplot2)
library(dplyr)
library(RColorBrewer)

# Read pops
pops <- read.table(file = "../03.GEA/BANS_sample_list_pop.tsv", sep="\t", header = FALSE)  %>%
  rename(ind = V1, Cluster = V3) %>%
  dplyr::select(ind, Cluster)

# Join PCA data
pca.cluster <- left_join(pca05, pops, by="ind")  # left_join PCA first to preserve PC columns

# Factor for cluster order
region_order <- c(
  "Cluster_1", "Cluster_5", 
  "Cluster_4", "Cluster_8", "Cluster_12", "Cluster_2", "Cluster_3", "Cluster_7",
  "Cluster_11", "Cluster_14", "Cluster_13", "Cluster_6", "Cluster_9", "Cluster_10"
)
pca.cluster$Cluster <- factor(pca.cluster$Cluster, levels = region_order)

# Define clusters by region
West_clusters    <- c("Cluster_1", "Cluster_5")
Midwest_clusters <- c("Cluster_4", "Cluster_8", "Cluster_12", "Cluster_2", "Cluster_3", "Cluster_7")
East_clusters    <- c("Cluster_11", "Cluster_14", "Cluster_13", "Cluster_6", "Cluster_9", "Cluster_10")

# Assign colors by cluster
W.cols <- setNames(brewer.pal(n = length(West_clusters), "Reds"), West_clusters)
Midwest.cols <- setNames(brewer.pal(n = length(Midwest_clusters), "Blues"), Midwest_clusters)
E.cols <- setNames(brewer.pal(n = length(East_clusters), "Greens"), East_clusters)
bg <- c(W.cols, Midwest.cols, E.cols)

# Plot
b05 <- ggplot(pca.cluster, aes(PC1, PC2, col = Cluster)) +
  geom_point(size = 3) +
  scale_color_manual(values = bg) +
  coord_equal() + 
  theme_light() +
  xlab(paste0("PC1 (", signif(pve05$pve[1], 3), "%)")) +
  ylab(paste0("PC2 (", signif(pve05$pve[2], 3), "%)"))

b05

ggsave("BANS_overall_PCA.png", width=8)

```

# Getting MEMS

```{r}
## mems
# read in coordinates from metadata file and filter for individuals in indorder
coords <- read_csv("../../data/BANS_sample_data.csv") %>%
  rename(BGP_ID = "BGP ID") %>% 
  filter(BGP_ID %in% indorder$BGP_ID) %>% 
  dplyr::select(BGP_ID, Long, Lat)

# reorder coordinates to match PCA data
coords <- coords[(match(indorder$BGP_ID, coords$BGP_ID)),]

coords_sf <- st_as_sf(coords, coords = c("Long", "Lat"), crs = 4326)

gd <- geosphere::distm(as(coords_sf, "Spatial"), fun = geosphere::distHaversine)
dist <- as.dist(gd)

# generate moran's eigenvector maps (MEMs) based on coordinates
mem <- adespatial::dbmem(dist, MEM.autocor = "all")

#moran_test <- moran.randtest(mem)

# rda to assess how much MEMs explain genetic variation (PC1â€“PC2)
mem_rda <- vegan::rda(plink_pca[,c("PC1", "PC2")] ~ ., as.data.frame(mem[,1:10]))
summary(mem_rda)

# create a null (intercept-only) rda model as a baseline
mem_rda_full <- vegan::rda(plink_pca[,c("PC1", "PC2")] ~ 1, as.data.frame(mem[,1:10]))
summary(mem_rda_full)

# stepwise forward selection of mem variables based on adjusted R-square and significance
selmem <- vegan::ordiR2step(mem_rda_full, mem_rda, Pin = .01)
summary(selmem)
# extract the names of the selected mem variables
selmem <- names(selmem$terminfo$ordered)

# subset the mem matrix to include only the mems that explain population structure
mem_popstr <- mem[,selmem]

saveRDS(mem_popstr, file = "BANS.mems.popstr.rds")
#mem_popstr <- read_rds("BANS.mems.popstr.rds")
```

```{r}
coords_mems_pc <- cbind(coords, mem, plink_pca[,c("PC1", "PC2")])

map <- rnaturalearth::ne_states(country = c("United States of America", "Canada", "Mexico"), returnclass = 'sf')

# plot the populations you defined. use plotly to zoom around easy
mem4_map<- ggplot(map) + geom_sf() + geom_point(data = coords_mems_pc, aes(x = Long, y = Lat, color = MEM4, BGP_ID = BGP_ID)) +
coord_sf(xlim = c(-125, -70), ylim = c(23, 58)) + scale_color_viridis_c()
ggsave("mem4_map.pdf", mem4_map, width = 8, height = 6)


plot(coords_mems_pc[,c("PC1", "PC2", paste0("MEM",1:9))])
```


I'm going to do a subset of 10,000 snps like brenna does.
```{r}
library(data.table)
library(adegenet)
library(adegenet)

# Load PLINK raw file as a genlight object
plink_data <- read.PLINK("../../data/subsampled_noheader.raw")

# Convert genlight to genotype matrix
geno_matrix <- as.matrix(plink_data)

# Keep SNP names
snp_names <- locNames(plink_data)  
length(snp_names)
# Recreate genlight object with SNP names
plink_subset <- new("genlight", geno_matrix, loc.names = snp_names, ind.names = indNames(plink_data))
nrow(plink_subset)
# Save as CSV
geno_df <- as.data.frame(plink_subset)
nrow(plink_subset)

write.table(geno_df, "subset_10000_snps.csv", sep = ",", quote = FALSE, row.names = TRUE)

subset <- read.csv("subset_10000_snps.csv")
env <- fread("BANS.climtop6.txt")
pop <- fread("BANS_sample_list_pop.tsv", header = F)  %>% dplyr::select(-V2) %>% rename(BGP_ID = V1, ClimGroup = V3)

bgp_ids <- data.frame(BGP_ID = rownames(subset))
pop <- pop %>% slice(match(bgp_ids$BGP_ID, pop$BGP_ID)) ## make ind same order as snpfile & env data
env <- cbind(pop, env)

##modify data types like brenna did...

# Convert BGP_ID to character (to avoid factor-related issues)
env[, BGP_ID := as.character(BGP_ID)]

# Convert ClimGroup to a factor if it's categorical
env[, ClimGroup := as.factor(ClimGroup)]

all(rownames(subset) == env$BGP_ID)

pred <- subset(env, select=c("bio02", "bio05", "bio07", "bio03"))

pred_mems <- cbind(pred, as.data.frame(mem_popstr))

pred_pc <- cbind(pred, plink_pca %>% dplyr::select(PC1, PC2))

bans.subset.ind.rda <- rda(subset ~ ., data=pred, scale=T)

```

One thing the paper that I saw in the paper recommending this did afterwards was select MEMs from the final set (selmem) which are uncorrelated with your selected environmental variables as well. You can do that like:
```{r}
corselmem <- cor(mem[,selmem], pred) # remove any correlated
# identify variables with correlation >= 0.7 with *any other variable*
highcor <- rownames(corselmem)[apply(abs(corselmem) >= 0.7, 1, any)]

# remove those
uncorselmem <- mem[, selmem]
uncorselmem <- uncorselmem[, !(colnames(uncorselmem) %in% highcor), drop = FALSE]

saveRDS(uncorselmem, file = "bans.mems.popstr.uncor.rds")
```

# RDA
```{r}
### 1. Fit RDAs ----
# Baseline (env only)
rda_env      <- rda(subset ~ bio02 + bio05 + bio07 + bio03, data = pred, scale = TRUE)

# Control for MEMs (full, uncorrelated, single MEM1)
rda_env_mems <- rda(subset ~ bio02 + bio05 + bio07 + bio03 +
                      Condition(MEM1 + MEM5 + MEM4 + MEM3 + MEM7),
                    data = pred_mems, scale = TRUE)

rda_env_mems_uncor <- rda(subset ~ bio02 + bio05 + bio07 + bio03 +
                            Condition(MEM4 + MEM3 + MEM7),
                          data = pred_mems, scale = TRUE)

rda_env_mem1 <- rda(subset ~ bio02 + bio05 + bio07 + bio03 +
                      Condition(MEM1),
                    data = pred_mems, scale = TRUE)

# Control for PCs
rda_env_pc1   <- rda(subset ~ bio02 + bio05 + bio07 + bio03 +
                       Condition(PC1),
                     data = pred_pc, scale = TRUE)

rda_env_pc12  <- rda(subset ~ bio02 + bio05 + bio07 + bio03 +
                       Condition(PC1 + PC2),
                     data = pred_pc, scale = TRUE)


# ### 2. Model comparisons ----
# # Adjusted R2
# RsquareAdj(rda_env)
# RsquareAdj(rda_env_mems)
# RsquareAdj(rda_env_mems_uncor)
# RsquareAdj(rda_env_mem1)
# RsquareAdj(rda_env_pc1)
# RsquareAdj(rda_env_pc12)
# 
# # Eigenvalues (variance explained by constrained axes)
# summary(eigenvals(rda_env, model = "constrained"))
# summary(eigenvals(rda_env_mems, model = "constrained"))
# 
# # Significance (example with MEMs)
# anova.cca(rda_env_mems, parallel = getOption("mc.cores"))
# 
# # VIF (check collinearity among predictors)
# vif.cca(rda_env_mems)


### 3. Plots ----
# Baseline
plot(rda_env, scaling = 3)
plot(rda_env, choices = c(1, 3), scaling = 3)

# MEMs
plot(rda_env_mems, scaling = 3)
plot(rda_env_mems, choices = c(1, 3), scaling = 3)
plot(rda_env_mems_uncor, scaling = 3)
plot(rda_env_mem1, scaling = 3)

# PCs
plot(rda_env_pc1, scaling = 3)
plot(rda_env_pc1, choices = c(1, 3), scaling = 3)
plot(rda_env_pc12, scaling = 3)
```

## model comparison
ChatGPT is gonna make the model comparison easy for me:
```{r}
### Helper function to extract key stats from an RDA ----
rda_summary <- function(model, name) {
  r2   <- RsquareAdj(model)$adj.r.squared
  pval <- anova.cca(model, parallel = getOption("mc.cores"))$`Pr(>F)`[1]  # model-level test
  eigvals <- eigenvals(model, model = "constrained")
  axis1_var <- eigvals[1] / sum(eigvals) # variance on axis 1
  data.frame(Model = name, AdjR2 = r2, Pval = pval, Axis1_var = axis1_var)
}

### Build comparison table ----
results <- rbind(
  rda_summary(rda_env,        "Env only"),
  rda_summary(rda_env_mems,   "Env + MEMs"),
  rda_summary(rda_env_mems_uncor, "Env + MEMs (uncor)"),
  rda_summary(rda_env_mem1,   "Env + MEM1"),
  rda_summary(rda_env_pc1,    "Env + PC1"),
  rda_summary(rda_env_pc12,   "Env + PC1+PC2")
)

print(results)

```
## plotting RDA results
```{r}
library(RColorBrewer)
clim_groups <- unique(env$ClimGroup)
eco <- factor(env$ClimGroup, levels = clim_groups)  # Ensure factor levels match
bg <- colorRampPalette(brewer.pal(min(12, length(clim_groups)), "Paired"))(length(clim_groups))


```

```{r}
load.rda <- scores(rda_env_mems_uncor, choices = c(1:3), display = "species")

par(mfrow = c(1,3))
hist(load.rda[,1], breaks = 50, main = "Loadings on RDA1", xlab = "SNP loading")
hist(load.rda[,2], breaks = 50, main = "Loadings on RDA2", xlab = "SNP loading")
hist(load.rda[,3], breaks = 50, main = "Loadings on RDA3", xlab = "SNP loading")
par(mfrow = c(1,1))

```
### working through different grouping options
```{r}
library(vegan)
library(plotly)

# Extract site (individual) scores and environmental (bp) scores
site_scores <- scores(rda_env_mems_uncor, display = "sites", scaling = 3)
bp_scores   <- scores(rda_env_mems_uncor, display = "bp", scaling = 3)

# Convert to data frames
sites_df <- data.frame(site_scores, 
                       PopID = env$ClimGroup,      # or whatever column holds population/region IDs
                       IndID = rownames(site_scores))  

bp_df <- data.frame(bp_scores, Var = rownames(bp_scores))

# Plotly scatter plot for individuals
p <- plot_ly(data = sites_df, 
             x = ~RDA1, y = ~RDA2, 
             type = "scatter", mode = "markers",
             text = ~paste("Pop:", PopID, "<br>ID:", IndID),
             marker = list(size = 8, color = "lightgray", 
                           line = list(color = "black", width = 0.5))) %>%
  layout(title = "RDA (Env + MEMs uncorrelated)",
         xaxis = list(title = "RDA1"),
         yaxis = list(title = "RDA2"))

# Add environmental predictor vectors
p <- p %>%
  add_trace(data = bp_df, x = ~RDA1, y = ~RDA2,
            type = "scatter", mode = "text+markers",
            text = ~Var, textposition = "top center",
            marker = list(size = 1, color = "blue"))

p
```

```{r}
library(sf)
library(mapview)

env.sf <- st_as_sf(env, coords = c("Long", "Lat"), crs = 4326 )
mapview(env.sf)

region_order <- c(
  "Cluster_1", "Cluster_5", 
  "Cluster_4", "Cluster_8", "Cluster_12", "Cluster_2", "Cluster_3", "Cluster_7",
  "Cluster_11", "Cluster_14", "Cluster_13", "Cluster_6", "Cluster_9", "Cluster_10"
)

eco <- factor(env$ClimGroup, levels = region_order)

bg <- colorRampPalette(brewer.pal(min(12, length(unique(eco))), "Paired"))(length(unique(eco)))

# Define your clusters grouped into regions
West_clusters    <- c("Cluster_1", "Cluster_5")
Midwest_clusters <- c("Cluster_4", "Cluster_8", "Cluster_12", "Cluster_2", "Cluster_3", "Cluster_7")
East_clusters    <- c("Cluster_11", "Cluster_14", "Cluster_13", "Cluster_6", "Cluster_9", "Cluster_10")

# Assign colors by region
W.cols <- setNames(brewer.pal(n = length(West_clusters), "Reds"), West_clusters)
Midwest.cols <- setNames(brewer.pal(n = length(Midwest_clusters), "Blues"), Midwest_clusters)
E.cols <- setNames(brewer.pal(n = length(East_clusters), "Greens"), East_clusters)

# Combine into one named vector
bg <- c(W.cols, Midwest.cols, E.cols)

# Reorder bg to match your factor order
bg <- bg[region_order]

# Check with barplot
barplot(rep(1, length(bg)), col = bg, border = NA, names.arg = names(bg), las = 2)

pdf("bans.subset.ind.rda.12.area_group.pdf")
par(mar=c(5, 5, 4, 8))
plot(rda_env_mems_uncor, type="n", scaling=3)  # Set up empty plot
#points(rda_env_mems_uncor, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[eco]) # Individuals
points(rda_env_mems_uncor, display="sites", pch=21, cex=1.3,
       col="gray32", scaling=3, bg=bg[as.character(eco)])
text(rda_env_mems_uncor, scaling=3, display="bp", col="black", cex=1)  # Predictors
#legend("bottomright", legend=levels(eco), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
#legend("bottomright", legend=levels(eco), bty="n", col="gray32", pch=21, cex=0.6, pt.bg=bg)
dev.off()
```

```{r}
region_order <- c(
  "WA_1", "OR_1", "CA_2", "CA_3", "NV_2", "MT_2", "CO_1", "UT_1", "AZ_1",
  "TX_1", "TX_2", "OK_1", "AR_1", "MS_1", "AL_1", "KY_2", "TN_1", "TN_2", "IN_1", "IL_1",
  "Ontario_1", "Ontario_2",
  "NC_1", "NC_2", "VA_1", "VA_2", "WV_1", "FL_1", "LA_1",
  "Manitoba_1", "Saskatchewan_1", "Alberta_1", "SD_2"
)

eco <- factor(env$ClimGroup, levels = region_order)

# generate colors based on the reordered factor
bg <- colorRampPalette(brewer.pal(min(12, length(unique(eco))), "Paired"))(length(unique(eco)))

# check colors
barplot(rep(1, 33), col = bg, border = NA)


# factor.levels <- c("WA_1", "OR_1", "CA_2", "CA_3", "NV_2", "CO_1", "UT_1", "AZ_1",
#                    "TX_1", "TX_2", "OK_1", "AR_1", "MS_1", "AL_1", 
#                    "KY_2", "TN_1", "TN_2", "IN_1", "IL_1",
#                    "Ontario_1", "Ontario_2",
#                    "Manitoba_1", "Saskatchewan_1", "Alberta_1", "SD_2", "MT_2",
#                    "NC_1", "NC_2", "VA_1", "VA_2", "WV_1", "FL_1", "LA_1"
#                    )
# 
# # Define the correct number of colors for each region
# W.cols <- brewer.pal(n = 9, name = "Reds")[2:9]          
# M.cols <- brewer.pal(n = 6, name = "Greys")[2:7]  
# Midwest.cols <- brewer.pal(n = 9, name = "Blues")[c(1, 3, 5, 7, 9)]  
# Ont.cols <- rep("turquoise4", 2)
# Plains.cols <- brewer.pal(n = 5, name = "Greens")[c(3:7)]  
# SE.cols <- brewer.pal(n = 7, name = "Purples")[1:7] 
# 
# bg <- c(W.cols, M.cols, Midwest.cols, Ont.cols, Plains.cols, SE.cols)
# names(bg) <- factor.levels
# 
# barplot(rep(1, 33), col = bg, border = NA)

# W.cols <- setNames(brewer.pal(n = 9, name = "Reds")[2:9], 
#                    c("WA_1", "OR_1", "CA_2", "CA_3", "NV_2", "CO_1", "UT_1", "AZ_1"))
# M.cols <- setNames(brewer.pal(n = 9, name = "Greys")[c(1, 3, 5, 7, 9)], 
#                    c("TX_1", "TX_2", "OK_1", "AR_1", "MS_1"))
# Midwest.cols <- setNames(brewer.pal(n = 9, name = "Blues")[c(1, 3, 5, 7, 9)],
#                          c("KY_2", "TN_1", "TN_2", "IN_1", "IL_1"))
# Ont.cols <- setNames(rep("turquoise4", 2), c("Ontario_1", "Ontario_2"))
# 
# Plains.cols <- setNames(brewer.pal(n = 7, name = "Greens")[c(3:7)],
#                         c("Manitoba_1", "Saskatchewan_1", "Alberta_1", "SD_2", "MT_2"))
# SE.cols <- setNames(brewer.pal(n = 9, name = "Purples")[2:9],
#                     c("NC_1", "NC_2", "VA_1", "VA_2", "WV_1", "FL_1", "LA_1", "AL_1"))

W.cols <- setNames(brewer.pal(n = 9, name = "Reds")[2:9], 
                   c("WA_1", "OR_1", "CA_2", "CA_3", "NV_2", "CO_1", "UT_1", "AZ_1"))

# Modify M.cols: Remove AL_1
M.cols <- setNames(brewer.pal(n = 6, name = "Greys")[2:6],  # one fewer color
                   c("TX_1", "TX_2", "OK_1", "AR_1", "MS_1"))

# Midwest
Midwest.cols <- setNames(brewer.pal(n = 9, name = "Blues")[c(1, 3, 5, 7, 9)],
                         c("KY_2", "TN_1", "TN_2", "IN_1", "IL_1"))

# Ontario
Ont.cols <- setNames(rep("turquoise4", 2), c("Ontario_1", "Ontario_2"))

# Plains
Plains.cols <- setNames(brewer.pal(n = 7, name = "Greens")[3:7],
                        c("Manitoba_1", "Saskatchewan_1", "Alberta_1", "SD_2", "MT_2"))

# SE: Add AL_1 at the end
SE.cols <- setNames(brewer.pal(n = 9, name = "Purples")[2:9],
                    c("NC_1", "NC_2", "VA_1", "VA_2", "WV_1", "FL_1", "LA_1", "AL_1"))

# Combine all named color vectors
bg <- c(W.cols, M.cols, Midwest.cols, Ont.cols, Plains.cols, SE.cols)

# Reorder bg to match factor.levels explicitly
bg <- bg[factor.levels]

# Plot to check
barplot(rep(1, length(bg)), col = bg, border = NA)

```

```{r}
pdf("bans.subset.ind.rda.12.pdf")
par(mar=c(5, 5, 4, 8))
plot(rda_env_mems_uncor, type="n", scaling=3)  # Set up empty plot
#points(losh.subset.ind.rda.memps, display="species", pch=20, cex=0.7, col="gray32", scaling=3) # SNPs
points(rda_env_mems_uncor, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[eco]) # Individuals
text(rda_env_mems_uncor, scaling=3, display="bp", col="#0868ac", cex=1)  # Predictors
#legend("bottomright", legend=levels(eco), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
#legend("bottomright", legend=levels(eco), bty="n", col="gray32", pch=21, cex=0.6, pt.bg=bg)
dev.off()

# plot(losh.subset.ind.rda.memps, type="n",choices=c(1,3), scaling=3)  # Set up empty plot
# points(losh.subset.ind.rda.memps, display="species", pch=20, cex=0.7, col="gray32", scaling=3) # SNPs
# points(losh.subset.ind.rda.memps, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[eco]) # Individuals
# text(losh.subset.ind.rda.memps, scaling=3, display="bp", col="#0868ac", cex=1)  # Predictors
# #legend("bottomright", legend=levels(eco), bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
# legend("bottomright", legend=levels(eco), bty="n", col="gray32", pch=21, cex=0.6, pt.bg=bg)


# mapping them too
coords_env <- left_join(coords, env, by = "BGP_ID")

# plotly::ggplotly(ggplot(map) + geom_sf() + geom_point(data = coords_env, aes(x = Long, y = Lat, color = ClimGroup, BGP_ID = BGP_ID)) + scale_fill_manual(values = bg, name = "ClimGroup") +
# coord_sf(xlim = c(-140, -65), ylim = c(23, 60)))

p <- ggplot(map) +
  geom_sf(fill = "gray95", color = "white") +
  geom_sf(
    data = coords_env, aes(fill = ClimGroup),
    shape = 21, size = 3, color = "black", stroke = 0.2
  ) +
  scale_fill_manual(values = bg, name = "ClimGroup") +
  coord_sf(xlim = c(-140, -65), ylim = c(23, 60)) +
  theme_minimal()
ggsave("losh.subset.ind.rda.memps.map.pdf", p, width = 8, height = 6)

# Interactive plot with tooltips
plotly::ggplotly(p, tooltip = c("text", "fill"))
p

par(mar=c(5, 5, 4, 8))
plot(losh.subset.ind.rda.memps, type="n", scaling=3)  # Set up empty plot
#points(losh.subset.ind.rda.memps, display="species", pch=20, cex=0.7, col="gray32", scaling=3) # SNPs
points(losh.subset.ind.rda.memps, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[eco]) # Individuals
text(losh.subset.ind.rda.memps, scaling=3, display="bp", col="#0868ac", cex=1)

```



# following the correct brenna tutorial
```{r}
losh.ind.rda.4 <- readRDS("data/losh.ind.rda.top4clim.memps.rds")
losh.ind.rda.6 <- readRDS("data/losh.ind.rda.top6clim.memps.rds")
RsquareAdj(losh.ind.rda.6)
summary(eigenvals(losh.ind.rda.6, model = "constrained"))
screeplot(losh.ind.rda.6)
```

```{r}
RsquareAdj(losh.ind.rda)
```
```
$r.squared
[1] 0.06129724

$adj.r.squared
[1] 0.0469659
```
The adjusted r-square explains ~ 5% of the variance

```{r}
summary(eigenvals(losh.ind.rda.3, model = "constrained"))
```
```
Importance of components:
                           RDA1      RDA2      RDA3      RDA4
Eigenvalue            5.523e+04 1.558e+04 7.949e+03 5.580e+03
Proportion Explained  6.548e-01 1.848e-01 9.424e-02 6.615e-02
Cumulative Proportion 6.548e-01 8.396e-01 9.338e-01 1.000e+00
```
The proportion of variance explained by each PC is: RDA1: 65.48%, RDA2: 18.48%, RDA3: 9.42%, RDA4: 6.62%


```{r}

## Not sure how to get these lines to run. Seem to stall out??

# signif.full <- anova.cca(losh.ind.rda, parallel=getOption("mc.cores")) # default is permutation=999
# signif.full

# signif.axis <- anova.cca(losh.ind.rda, by="axis", parallel=getOption("mc.cores"))
# signif.axis

plot(losh.ind.rda.4, scaling=3)
```


```{r}
# pop.xy <- read_csv("../../meta/losh_master_092924.csv") %>%
#   filter(BGP_ID %in% pop$BGP_ID) %>% left_join(pop, by = "BGP_ID") %>% dplyr::select(BGP_ID, ClimGroup, Lat, Long)
# 
# group_centroids <- pop.xy %>%
#   group_by(ClimGroup) %>%
#   summarize(
#     mean_lat = mean(Lat, na.rm = TRUE),
#     mean_long = mean(Long, na.rm = TRUE)
#   )
# 
# geo_pca <- prcomp(group_centroids[, c("mean_long", "mean_lat")], scale. = TRUE)
# 
# # use the first principal component (PC1) as the gradient axis
# group_centroids$geo_score <- geo_pca$x[, 1]
# 
# # arrange by PC1 (diagonal axis)
# group_centroids <- group_centroids %>%
#   arrange(geo_score)
# 
# # create a color palette with as many unique ClimGroups as needed
# geo_colors <- colorRampPalette(brewer.pal(min(12, nrow(group_centroids)), "YlGnBu"))(nrow(group_centroids))
# 
# # assign colors to ClimGroups
# group_centroids$color <- geo_colors
# 
# # create a named vector for easy mapping later
# clim_colors <- setNames(group_centroids$color, group_centroids$ClimGroup)
# 
# pop.xy$color <- clim_colors[pop.xy$ClimGroup]
# 
# barplot(rep(1, length(clim_colors)), col = clim_colors, border = NA,
#         names.arg = names(clim_colors), las = 2, cex.names = 0.7)
# 
# geo_order <- group_centroids$ClimGroup
# eco <- factor(env$ClimGroup, levels = geo_order)
# 
# # create bg color vector matching individuals in env to geographic colors
# bg <- clim_colors[as.character(eco)]


pop.xy <- read_csv("../../meta/losh_master_092924.csv") %>%
  filter(BGP_ID %in% pop$BGP_ID) %>%
  left_join(pop, by = "BGP_ID") %>%
  select(BGP_ID, ClimGroup, Lat, Long)

# Calculate centroids per ClimGroup
group_centroids <- pop.xy %>%
  group_by(ClimGroup) %>%
  summarize(
    mean_lat = mean(Lat, na.rm = TRUE),
    mean_long = mean(Long, na.rm = TRUE),
    .groups = "drop"
  )

# Arrange by **mean latitude** for north-south gradient
group_centroids <- group_centroids %>%
  arrange(desc(mean_lat))  # Descending so that northern groups are at the top

# Generate geographic color gradient
geo_colors <- colorRampPalette(brewer.pal(min(12, nrow(group_centroids)), "YlGnBu"))(nrow(group_centroids))

# Assign colors to ClimGroups
group_centroids$color <- geo_colors
clim_colors <- setNames(group_centroids$color, group_centroids$ClimGroup)

# Map colors to each population point
pop.xy$color <- clim_colors[pop.xy$ClimGroup]

# Optional: show color bar
barplot(rep(1, length(clim_colors)), col = clim_colors, border = NA,
        names.arg = names(clim_colors), las = 2, cex.names = 0.7)

# Create ordered factor for plotting
geo_order <- group_centroids$ClimGroup
eco <- factor(env$ClimGroup, levels = geo_order)

# Assign colors to individuals for plotting
bg <- clim_colors[as.character(eco)]
```

# make this plot colorful
```{r}
all(rownames(env) == rownames(losh.ind.rda.6)) ##order matches if TRUE
## it does

plot(losh.ind.rda.6, type = "n", scaling = 3)  # Empty RDA plot
#points(losh.ind.rda.6, display = "species", pch = 20, cex = 0.7, col = "gray32", scaling = 3)  # SNPs
points(losh.ind.rda.6, display = "sites", pch = 21, cex = 1.3, col = "gray32", scaling = 3, bg = bg[eco])  # Individuals
text(losh.ind.rda.6, scaling = 3, display = "bp", col = "#0868ac", cex = 1)  # Predictors
#legend("bottomright", legend = levels(eco), bty = "n", col = "gray32", pch = 21, pt.bg = bg, cex = 0.6)

```

## plot pop region colors
```{r}
W.cols <- setNames(brewer.pal(n = 9, name = "Reds")[2:9], 
                   c("WA_1", "OR_1", "CA_2", "CA_3", "NV_2", "CO_1", "UT_1", "AZ_1"))
# Modify M.cols: Remove AL_1
M.cols <- setNames(brewer.pal(n = 6, name = "Greys")[2:6],  # one fewer color
                   c("TX_1", "TX_2", "OK_1", "AR_1", "MS_1"))
# Midwest
Midwest.cols <- setNames(brewer.pal(n = 9, name = "Blues")[c(1, 3, 5, 7, 9)],
                         c("KY_2", "TN_1", "TN_2", "IN_1", "IL_1"))
# Ontario
Ont.cols <- setNames(rep("turquoise4", 2), c("Ontario_1", "Ontario_2"))
# Plains
Plains.cols <- setNames(brewer.pal(n = 7, name = "Greens")[3:7],
                        c("Manitoba_1", "Saskatchewan_1", "Alberta_1", "SD_2", "MT_2"))
# SE: Add AL_1 at the end
SE.cols <- setNames(brewer.pal(n = 9, name = "Purples")[2:9],
                    c("NC_1", "NC_2", "VA_1", "VA_2", "WV_1", "FL_1", "LA_1", "AL_1"))
# Combine all named color vectors
bg <- c(W.cols, M.cols, Midwest.cols, Ont.cols, Plains.cols, SE.cols)
# Reorder bg to match factor.levels explicitly
#bg <- bg[factor.levels]
# Plot to check
barplot(rep(1, length(bg)), col = bg, border = NA)

p <- ggplot(map) +
  geom_sf(fill = "gray95", color = "white") +
  geom_point(
    data = coords_env,
    aes(x = Long, y = Lat, fill = ClimGroup, text = BGP_ID),
    shape = 21, size = 3, color = "black", stroke = 0.2
  ) +
  scale_fill_manual(values = bg, name = "ClimGroup") +
  coord_sf(xlim = c(-140, -65), ylim = c(23, 60)) +
  theme_minimal()


#eco <- meta$EcoRegion[match(rownames(losh.ind.rda.6$sites), meta$SampleID)]

# Interactive plot with tooltips
plotly::ggplotly(p, tooltip = c("text", "fill"))
p

pdf("losh.ind.rda.6.memps.pdf")
par(mar=c(5, 5, 4, 8))
plot(losh.ind.rda.6, type="n", scaling=3)  # Set up empty plot
#points(losh.subset.ind.rda.memps, display="species", pch=20, cex=0.7, col="gray32", scaling=3) # SNPs
points(losh.ind.rda.6, display="sites", pch=21, cex=1.3, col="gray32", scaling=3, bg=bg[eco]) # Individuals
text(losh.ind.rda.6, scaling=3, display="bp", col="#0868ac", cex=1)
dev.off()
```





# select outlier snps
```{r}

load.rda <- scores(rda_env_mems_uncor, choices=c(1:3), display="species")

hist(load.rda[,1], main="Loadings on RDA1")
hist(load.rda[,2], main="Loadings on RDA2")
hist(load.rda[,3], main="Loadings on RDA3")

outliers <- function(x,z){
  lims <- mean(x) + c(-1, 1) * z * sd(x)   #find loadings +/-z sd from mean loading     
  x[x < lims[1] | x > lims[2]]             #locus names in these tails
}

cand1 <- outliers(load.rda[,1],3) # 75998
cand2 <- outliers(load.rda[,2],3) # 63347
cand3 <- outliers(load.rda[,3],3) # 63725

##Find total # candidates
ncand <- length(cand1) + length(cand2) + length(cand3)

df.cand1 <- cbind.data.frame(rep(1,times=length(cand1)), names(cand1), unname(cand1))
df.cand2 <- cbind.data.frame(rep(2,times=length(cand2)), names(cand2), unname(cand2))
df.cand3 <- cbind.data.frame(rep(3,times=length(cand3)), names(cand3), unname(cand3))

colnames(df.cand1) <- colnames(df.cand2) <- colnames(df.cand3) <- c("axis","snp","loading")

df.cand <- rbind(df.cand1, df.cand2, df.cand3)
df.cand$snp <- as.character(df.cand$snp)

df.cand$snp <- gsub("-", ".", df.cand$snp)

pred <- subset(env, select=c(bio02 + bio05 + bio07 + bio03))

##Add environmental correlations to candidate snps
foo <- matrix(nrow=(ncand), ncol=4)  #4 columns for 4 predictors
colnames(foo) <- c("bio02", "bio05", "bio07", "bio03")
pred2 <- pred[,1:4]

for (i in 1:length(df.cand$snp)) {
  nam <- df.cand[i,2]
  snp.gen <- subset[[nam]]
  foo[i,] <- apply(pred2,2,function(x) cor(x,snp.gen))
}

cand <- cbind.data.frame(df.cand,foo)

length(cand$snp[duplicated(cand$snp)])
foo <- cbind(cand$axis, duplicated(cand$snp)) 
table(foo[foo[,1]==1,2]) # no duplicates on axis 1
table(foo[foo[,1]==2,2]) # 18202 duplicates on axis 2
table(foo[foo[,1]==3,2]) # 18787 duplicates on axis 3
cand <- cand[!duplicated(cand$snp),] # remove duplicate detection

cols <- as.numeric(ncol(cand))
for (i in 1:length(cand$snp)) {
  bar <- cand[i,]
  cand[i,(cols+1)] <- names(which.max(abs(bar[4:cols]))) # gives the variable
  cand[i,(cols+2)] <- max(abs(bar[4:cols]))              # gives the correlation
}

colnames(cand)[cols+1] <- "predictor"
colnames(cand)[cols+2] <- "correlation"

table(cand$predictor)

#rda_env_mems_uncor
write.table(cand,"ind.rda.env_memp.uncor.cand.snps.txt",row.names=F,sep = "\t", quote=F)

cand <- read.table("ind.rda.env_memp.uncor.cand.snps.txt")
sel <- cand$snp
env <- cand$predictor
env[env=="bio02"] <- '#1b9e77'
env[env=="bio05"] <- '#d95f02'
env[env=="bio07"] <- "purple4"
env[env=="bio03"] <-  '#e7298a'

col.pred <- rownames(rda_env_mems_uncor$CCA$v) # pull the SNP names

for (i in 1:length(sel)) {           # color code candidate SNPs
  foo <- match(sel[i],col.pred)
  col.pred[foo] <- env[i]
}

col.pred[grep("scaffold",col.pred)] <- '#f1eef6' # non-candidate SNPs
col.pred[!grepl("^#", col.pred)] <- "#f1eef6"

col.pred[!col.pred %in% env] <- "gray80"
empty <- col.pred
empty.outline <- ifelse(empty %in% c("gray80"), "gray50", "black")

empty.outline <- ifelse(empty == "#00FF0000", "#00FF0000", "gray32")

bg <- c('#1b9e77','#d95f02',"purple4",'#e7298a')


plot(rda_env_mems_uncor, type="n", scaling=3, xlim=c(-1,1), ylim=c(-1,1))
#points(cawa2.rda, display="species", pch=21, cex=1, col="gray32", bg=col.pred, scaling=3)
points(rda_env_mems_uncor, display="species", pch=21, cex=1, col=empty.outline, bg=empty, scaling=3)
text(rda_env_mems_uncor, scaling=3, display="bp", col="#0868ac", cex=1)
legend("bottomright", legend=c("bio02","bio05","bio07","bio03"), 
    bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
```

# DOING ALL OF THIS ON THE CLUSTER
So, because I can't run the above stuff on all 1.whatever million SNPs on my local computer, I've got to convert all this into R scripts that can be run on my cluster. I wrote up the 03.2.RDA_cluster.R to run on the cluster. Here I'll just feed in some results to see what we're working with.

```{bash}
rsync -avzP ericacnr@colostate.edu@login.rc.colorado.edu:/scratch/alpine/ericacnr@colostate.edu/BANS/03.GEA/results /Users/ericarobertson/Desktop/BANS_adaptive_units/analysis/03.GEA/results/
```




