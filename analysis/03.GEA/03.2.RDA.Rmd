---
title: "RDA"
author: "Erica Robertson"
date: "2025-08-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir="~/Desktop/BANS/BANS_adaptive_units/")
```

```{r, label="packages"}
library(pegas)
library(ggplot2)
library(rnaturalearth)
library(rnaturalearthdata)
library(RColorBrewer)
library(ggpubr)
library(vegan)
library(robust)
library(ggVennDiagram)
library(cowplot)
library(corrplot)
library(data.table)
library(tidyverse)
library(qvalue) <----
library(adegenet)
library(dplyr)
```


# Reformatting vcf with PLINK
```{bash}
bfile="/scratch/alpine/ericacnr@colostate.edu/BANS/02.5.neutral_pop_struc/pruned_allindv"
conda activate GWAS2

plink -bfile $bfile --aec --recode A --out pruned_allindv
```

This generates the following files:
pruned_allindv.log
pruned_allindv.nosex
pruned_allindv.raw

With the recode A function 
-Each genotype is coded as 0, 1, or 2, representing the number of copies of the alternate (usually minor) allele an individual has at each SNP.
-Missing genotypes are typically coded as -1.

Recommended next step is to cut the header off the plink file before moving it into R, for downstream stuff to work.

```{bash}
cut -d$'\t' -f7- pruned_allindv.raw > pruned_allindv_noheader.raw
```

# Loading data into R

Now we need to get the allele frequency and environmental data into R. This isn't going to run well on your local computer unless you only have a small subset of SNPs. A good way to do this is sample your vcf and move over a subset to test the scripts on your local machine, and then pop them back over to the cluster when they're ready to run on the full set.

I made the subsampled_noheader.raw for the RDA_env_vars file

```{bash}
rsync -avzP ericacnr@colostate.edu@login.rc.colorado.edu:/scratch/alpine/ericacnr@colostate.edu/BANS/02.5.neutral_pop_struc/pruned_allindv.fam /Users/ericarobertson/Desktop/BANS_adaptive_units/data
```

```{r}
pops <- read.table(file = "BANS_sample_list_pop.tsv", sep="\t", header = FALSE) %>% rename(BGP_ID = V1, Pop = V3) %>% dplyr::select(BGP_ID, Pop)

#all.freq <- fread("data/losh.33pop.frq.strat.50k_A.txt") ## instead of running on allele frequency per population, try running on individual genotypes...

genotypes <- fread("/Users/ericarobertson/Desktop/BANS_adaptive_units/data/subsampled_noheader.raw")

indorder <- fread("../../data/pruned_allindv.fam") %>% rename(BGP_ID = V1) %>% dplyr::select(BGP_ID)

env <- read.csv("BANS_topRDA_vars.csv")
```

```{r}
# source("./src/rdadapt.R")
# rdadapt_env_unconstrained <- rdadapt(RDA_env_unconstrained, 2)
# thres_env <- 0.01/length(rdadapt_env_unconstrained$p.values)
# 
# 
# ## Identifying the outliers for the simple RDA
# outliers_unconstrained <- data.frame(Loci = colnames(all.freq)[which(rdadapt_env_unconstrained$p.values<thres_env)], p.value = rdadapt_env_unconstrained$p.values[which(rdadapt_env_unconstrained$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(all.freq)[which(rdadapt_env_unconstrained$p.values<thres_env)], split = "_"), function(x) x[1])))
# outliers_unconstrained <- outliers_unconstrained[order(outliers_unconstrained$contig, outliers_unconstrained$p.value),]
# outliers_rdadapt_env_unconstrained <- as.character(outliers_unconstrained$Loci[!duplicated(outliers_unconstrained$contig)])
```

# Population Structure
I already did the overall population structure so I'm just going to read that info in.
```{r}
library(tidyverse)
plink_pca <- read.table("../02.5.delineate_ESUs/PC1_allindv_noimpute.ld25-10-0.5.eigenvec", header = F) %>% select(-V1)
eigenval <- scan("../02.5.delineate_ESUs/PC1_allindv_noimpute.ld25-10-0.5.eigenval")

# set names
names(plink_pca)[1] <- "ind"
colnames(plink_pca)[-1] <- paste0("PC", 1:(ncol(pca05) - 1))
nrow(plink_pca)
#correct number of samples

pve05 <- data.frame(PC = 1:208, pve = eigenval/sum(eigenval)*100)
pve05

a05 <- ggplot(pve05, aes(PC, pve)) + geom_bar(stat = "identity")+
  ylab("Percentage variance explained") + theme_light()
```



# Getting MEMS

```{r}
## mems
# read in coordinates from metadata file and filter for individuals in indorder
coords <- read_csv("../../data/BANS_all_sample_data.csv") %>%
  filter(BGP_ID %in% indorder$BGP_ID) %>% 
  dplyr::select(BGP_ID, Long, Lat)

# reorder coordinates to match PCA data
coords <- coords[(match(indorder$BGP_ID, coords$BGP_ID)),]

coords_sf <- st_as_sf(coords, coords = c("Long", "Lat"), crs = 4326)

gd <- geosphere::distm(as(coords_sf, "Spatial"), fun = geosphere::distHaversine)
dist <- as.dist(gd)

# generate moran's eigenvector maps (MEMs) based on coordinates
mem <- adespatial::dbmem(dist, MEM.autocor = "all")

#moran_test <- moran.randtest(mem)

# rda to assess how much MEMs explain genetic variation (PC1–PC2)
mem_rda <- vegan::rda(plink_pca[,c("PC1", "PC2")] ~ ., as.data.frame(mem[,1:10]))
summary(mem_rda)

# create a null (intercept-only) rda model as a baseline
mem_rda_full <- vegan::rda(plink_pca[,c("PC1", "PC2")] ~ 1, as.data.frame(mem[,1:10]))
summary(mem_rda_full)

# stepwise forward selection of mem variables based on adjusted R-square and significance
selmem <- vegan::ordiR2step(mem_rda_full, mem_rda, Pin = .01)
summary(selmem)
# extract the names of the selected mem variables
selmem <- names(selmem$terminfo$ordered)

# subset the mem matrix to include only the mems that explain population structure
mem_popstr <- mem[,selmem]

saveRDS(mem_popstr, file = "BANS.mems.popstr.rds")
```

```{r}
coords_mems_pc <- cbind(coords, mem, plink_pca[,c("PC1", "PC2")])

map <- rnaturalearth::ne_states(country = c("United States of America", "Canada", "Mexico"), returnclass = 'sf')

# plot the populations you defined. use plotly to zoom around easy
mem4_map<- ggplot(map) + geom_sf() + geom_point(data = coords_mems_pc, aes(x = Long, y = Lat, color = MEM4, BGP_ID = BGP_ID)) +
coord_sf(xlim = c(-125, -70), ylim = c(23, 58)) + scale_color_viridis_c()
ggsave("mem4_map.pdf", mem4_map, width = 8, height = 6)


plot(coords_mems_pc[,c("PC1", "PC2", paste0("MEM",1:9))])
```

I'm going to do a subset of 50,000 snps.
```{r}
library(data.table)
library(adegenet)
library(adegenet)

# Load PLINK raw file as a genlight object
plink_data <- read.PLINK("../../data/subsampled_noheader.raw")

# Convert genlight to genotype matrix
geno_matrix <- as.matrix(plink_data)

# Keep SNP names
snp_names <- locNames(plink_data)  
length(snp_names)
# Recreate genlight object with SNP names
plink_subset <- new("genlight", geno_matrix, loc.names = snp_names, ind.names = indNames(plink_data))
nrow(plink_subset)

geno_df <- as.data.frame(plink_subset)
nrow(plink_subset)
rownames(geno_df) <- env$BGP_ID

env <- fread("BANS_topRDA_vars.csv")
pop <- fread("BANS_sample_list_pop.tsv", header = F)  %>% dplyr::select(-V2) %>% rename(BGP_ID = V1, ClimGroup = V3)

bgp_ids <- data.frame(BGP_ID = rownames(geno_df))
env <- cbind(pop, env)

# Convert BGP_ID to character (to avoid factor-related issues)
env[, BGP_ID := as.character(BGP_ID)]

# Convert ClimGroup to a factor if it's categorical
env[, ClimGroup := as.factor(ClimGroup)]
saveRDS(env, "results/RDA_output/env.rds")

all(rownames(geno_df) == env$BGP_ID)

pred <- env[,8:17]

pred_mems <- cbind(pred, as.data.frame(mem_popstr))

pred_pc_mems_env <- cbind(pred_mems, plink_pca %>% dplyr::select(PC1, PC2))

#bans.subset.ind.rda <- rda(subset ~ ., data=pred, scale=T)
```

One thing the paper that I saw in the paper recommending this did afterwards was select MEMs from the final set (selmem) which are uncorrelated with your selected environmental variables as well. You can do that like:
```{r}
corselmem <- cor(mem[,selmem], pred) # remove any correlated
# identify variables with correlation >= 0.7 with *any other variable*
highcor <- rownames(corselmem)[apply(abs(corselmem) >= 0.7, 1, any)]

# remove those
uncorselmem <- mem[, selmem]
uncorselmem <- uncorselmem[, !(colnames(uncorselmem) %in% highcor), drop = FALSE]

saveRDS(uncorselmem, file = "bans.mems.popstr.uncor.rds")
```

# RDA
```{r}
### 1. Fit RDAs ----
# Baseline (env only)
rda_env <- rda(geno_df ~ Temperate.or.Subpolar.Shrubland + Subpolar.Taiga.Needleleaf.Forest + bio05 + Temperate.or.Subpolar.Grassland + Wetland + bio15 + clay + Temperate.or.Subpolar.Broadleaf.Deciduous.Forest + sand + bio02, data = pred_pc_mems_env, scale = TRUE)
saveRDS(rda_env, file = "results/RDA_output/rda_env.rds")

# Control for MEMs (full, uncorrelated, single MEM1)
rda_env_mems_uncor <- rda(geno_df ~ Temperate.or.Subpolar.Shrubland + Subpolar.Taiga.Needleleaf.Forest + bio05 + Temperate.or.Subpolar.Grassland + Wetland + bio15 + clay + Temperate.or.Subpolar.Broadleaf.Deciduous.Forest + sand + bio02 +
                      Condition(MEM1 + MEM8 + MEM2 + MEM6 + MEM4 + MEM9 + MEM10 + MEM5),
                    data = pred_pc_mems_env, scale = TRUE)
saveRDS(rda_env_mems_uncor, file = "results/RDA_output/rda_env_mems_uncor.rds")

rda_env_mem1 <- rda(geno_df ~ Temperate.or.Subpolar.Shrubland + Subpolar.Taiga.Needleleaf.Forest + bio05 + Temperate.or.Subpolar.Grassland + Wetland + bio15 + clay + Temperate.or.Subpolar.Broadleaf.Deciduous.Forest + sand + bio02 +
                      Condition(MEM1),
                    data = pred_pc_mems_env, scale = TRUE)

# Control for PCs
rda_env_pc1 <- rda(geno_df ~ Temperate.or.Subpolar.Shrubland + Subpolar.Taiga.Needleleaf.Forest + bio05 + Temperate.or.Subpolar.Grassland + Wetland + bio15 + clay + Temperate.or.Subpolar.Broadleaf.Deciduous.Forest + sand + bio02 +
                       Condition(PC1),
                     data = pred_pc_mems_env, scale = TRUE)

rda_env_pc12 <- rda(geno_df ~ Temperate.or.Subpolar.Shrubland + Subpolar.Taiga.Needleleaf.Forest + bio05 + Temperate.or.Subpolar.Grassland + Wetland + bio15 + clay + Temperate.or.Subpolar.Broadleaf.Deciduous.Forest + sand + bio02 +
                       Condition(PC1 + PC2),
                     data = pred_pc_mems_env, scale = TRUE)


# ### 2. Model comparisons ----
# # Adjusted R2
# RsquareAdj(rda_env)
# RsquareAdj(rda_env_mems)
# RsquareAdj(rda_env_mems_uncor)
# RsquareAdj(rda_env_mem1)
# RsquareAdj(rda_env_pc1)
# RsquareAdj(rda_env_pc12)
# 
# # Eigenvalues (variance explained by constrained axes)
# summary(eigenvals(rda_env, model = "constrained"))
# summary(eigenvals(rda_env_mems, model = "constrained"))
# 
# # Significance (example with MEMs)
# anova.cca(rda_env_mems, parallel = getOption("mc.cores"))
# 
# # VIF (check collinearity among predictors)
# vif.cca(rda_env_mems)


### 3. Plots ----
# Baseline
plot(rda_env, scaling = 3)
plot(rda_env, choices = c(1, 3), scaling = 3)

# MEMs
plot(rda_env_mems, scaling = 3)
plot(rda_env_mems, choices = c(1, 3), scaling = 3)
plot(rda_env_mems_uncor, scaling = 3)
plot(rda_env_mem1, scaling = 3)

# PCs
plot(rda_env_pc1, scaling = 3)
plot(rda_env_pc1, choices = c(1, 3), scaling = 3)
plot(rda_env_pc12, scaling = 3)
```

## model comparison
ChatGPT is gonna make the model comparison easy for me:
```{r}
### Helper function to extract key stats from an RDA ----
rda_summary <- function(model, name) {
  r2   <- RsquareAdj(model)$adj.r.squared
  pval <- anova.cca(model, parallel = getOption("mc.cores"))$`Pr(>F)`[1]  # model-level test
  eigvals <- eigenvals(model, model = "constrained")
  axis1_var <- eigvals[1] / sum(eigvals) # variance on axis 1
  data.frame(Model = name, AdjR2 = r2, Pval = pval, Axis1_var = axis1_var)
}

### Build comparison table ----
results <- rbind(
  rda_summary(rda_env,        "Env only"),
  rda_summary(rda_env_mems_uncor, "Env + MEMs (uncor)"),
  rda_summary(rda_env_mem1,   "Env + MEM1"),
  rda_summary(rda_env_pc1,    "Env + PC1"),
  rda_summary(rda_env_pc12,   "Env + PC1+PC2")
)

print(results)
```
## plotting RDA results
```{r}
clim_groups <- unique(env$ClimGroup)
eco <- factor(env$ClimGroup, levels = clim_groups)  # Ensure factor levels match
bg <- readRDS("../02.5.delineate_ESUs/bg_colors.rds")
```

```{r}
load.rda <- scores(rda_env_mems_uncor, choices = c(1:3), display = "species")

par(mfrow = c(1,3))
hist(load.rda[,1], breaks = 50, main = "Loadings on RDA1", xlab = "SNP loading")
hist(load.rda[,2], breaks = 50, main = "Loadings on RDA2", xlab = "SNP loading")
hist(load.rda[,3], breaks = 50, main = "Loadings on RDA3", xlab = "SNP loading")
par(mfrow = c(1,1))

```
```{r}
# ============================================================
# RDA biplot (plotly + PDF) — tidy version
# ============================================================
library(dplyr)
library(plotly)
library(RColorBrewer)
library(sf)
library(mapview)
library(vegan)
# ----------------------------
# Inputs you already have
# ----------------------------
rda_obj <- readRDS("results/RDA_output/rda_env_mems_uncor.rds")
env_df  <- readRDS("results/RDA_output/env.rds")

region_order <- c(
  "Cluster_1", "Cluster_5", "Cluster_16", "Cluster_4", "Cluster_9", "Cluster_12", "Cluster_2", "Cluster_20",
  "Cluster_3", "Cluster_8", "Cluster_17", "Cluster_21", "Cluster_18", "Cluster_19",
  "Cluster_6", "Cluster_14", "Cluster_11", "Cluster_10", "Cluster_13", "Cluster_15", "Cluster_7"
)

bg <- readRDS("../02.5.delineate_ESUs/bg_colors.rds")
bg <- bg[region_order]  # enforce consistent order

env_df  <- env_df[,-1:-3]                  # must contain your metadata (and Long/Lat if mapping)
group_col <- "Pop"              # change to "ClimGroup" if that's what you want
scaling_val <- 3

# ----------------------------
# 1) Extract scores
# ----------------------------
site_scores <- scores(rda_obj, display = "sites", scaling = scaling_val)
bp_scores   <- scores(rda_obj, display = "bp",    scaling = scaling_val)

sites_df <- as.data.frame(site_scores) %>%
  tibble::rownames_to_column(var="IndID")

bp_df <- as.data.frame(bp_scores) %>%
  tibble::rownames_to_column("Var")

# ----------------------------
# 2) Join group labels safely by ID
# ----------------------------
env2 <- env_df %>%
  select(BGP_ID, all_of(group_col)) %>%
  rename(PopID = all_of(group_col), IndID=BGP_ID)   # always call it PopID in the plotting df

sites_df <- left_join(sites_df, env2, by = "IndID")

# ============================================================
# PDF biplot (colored by ClimGroup)
# ============================================================

# Make factor with fixed order
eco <- factor(env_df$Pop, levels = region_order)

# Quick palette check
barplot(rep(1, length(bg)), col = bg, border = NA, names.arg = names(bg), las = 2)

eig <- summary(rda_obj)$cont$importance
eig
prop <- eig["Proportion Explained", ]
pct <- round(100 * prop, 1)
pct
xlab <- paste0("RDA1 (", pct[1], "%)")
ylab <- paste0("RDA2 (", pct[2], "%)")

pdf("bans.allind.rda_env_mems_uncor.pdf", width = 10, height = 8)
par(mar = c(5, 5, 4, 8))

plot(
  rda_obj,
  type = "n",
  scaling = 3,
  xlab = xlab,
  ylab = ylab
)

# sites
points(
  rda_obj,
  display = "sites",
  pch = 21,
  cex = 1.2,
  col = "gray32",
  bg  = bg[eco],
  scaling = 3
)

# bp vectors: draw arrows + labels (clearer than text-only)
bp <- scores(rda_obj, display = "bp", scaling = 3)

# compute a sensible multiplier
mul <- ordiArrowMul(bp)

arrows(
  0, 0,
  bp[, 1] * mul,
  bp[, 2] * mul,
  length = 0.08,
  col = "black"
)

text(
  bp[, 1] * mul,
  bp[, 2] * mul,
  labels = rownames(bp),
  col = "black",
  cex = 0.9,
  pos = 3
)

dev.off()

```

# select outlier snps
```{r}
rda_env_mems_uncor <- readRDS("results/RDA_output/rda_env_mems_uncor.rds")
load.rda <- scores(rda_env_mems_uncor, choices=c(1:3), display="species")

hist(load.rda[,1], main="Loadings on RDA1")
hist(load.rda[,2], main="Loadings on RDA2")
hist(load.rda[,3], main="Loadings on RDA3")

outliers <- function(x,z){
  lims <- mean(x) + c(-1, 1) * z * sd(x)   #find loadings +/-z sd from mean loading     
  x[x < lims[1] | x > lims[2]]             #locus names in these tails
}

cand1 <- outliers(load.rda[,1],3) # 160
cand2 <- outliers(load.rda[,2],3) # 185
cand3 <- outliers(load.rda[,3],3) # 170

##Find total # candidates
ncand <- length(cand1) + length(cand2) + length(cand3)

df.cand1 <- cbind.data.frame(rep(1,times=length(cand1)), names(cand1), unname(cand1))
df.cand2 <- cbind.data.frame(rep(2,times=length(cand2)), names(cand2), unname(cand2))
df.cand3 <- cbind.data.frame(rep(3,times=length(cand3)), names(cand3), unname(cand3))

colnames(df.cand1) <- colnames(df.cand2) <- colnames(df.cand3) <- c("axis","snp","loading")

df.cand <- rbind(df.cand1, df.cand2, df.cand3)
df.cand$snp <- as.character(df.cand$snp)

df.cand$snp <- gsub("-", ".", df.cand$snp)

pred <- subset(env, select=c(bio02 + bio05 + bio07 + bio03))

##Add environmental correlations to candidate snps
foo <- matrix(nrow=(ncand), ncol=4)  #4 columns for 4 predictors
colnames(foo) <- c("bio02", "bio05", "bio07", "bio03")
pred2 <- pred[,1:4]

for (i in 1:length(df.cand$snp)) {
  nam <- df.cand[i,2]
  snp.gen <- subset[[nam]]
  foo[i,] <- apply(pred2,2,function(x) cor(x,snp.gen))
}

cand <- cbind.data.frame(df.cand,foo)

length(cand$snp[duplicated(cand$snp)])
foo <- cbind(cand$axis, duplicated(cand$snp)) 
table(foo[foo[,1]==1,2]) # no duplicates on axis 1
table(foo[foo[,1]==2,2]) # 18202 duplicates on axis 2
table(foo[foo[,1]==3,2]) # 18787 duplicates on axis 3
cand <- cand[!duplicated(cand$snp),] # remove duplicate detection

cols <- as.numeric(ncol(cand))
for (i in 1:length(cand$snp)) {
  bar <- cand[i,]
  cand[i,(cols+1)] <- names(which.max(abs(bar[4:cols]))) # gives the variable
  cand[i,(cols+2)] <- max(abs(bar[4:cols]))              # gives the correlation
}

colnames(cand)[cols+1] <- "predictor"
colnames(cand)[cols+2] <- "correlation"

table(cand$predictor)

#rda_env_mems_uncor
write.table(cand,"ind.rda.env_memp.uncor.cand.snps.txt",row.names=F,sep = "\t", quote=F)

cand <- read.table("ind.rda.env_memp.uncor.cand.snps.txt")
sel <- cand$snp
env <- cand$predictor
env[env=="bio02"] <- '#1b9e77'
env[env=="bio05"] <- '#d95f02'
env[env=="bio07"] <- "purple4"
env[env=="bio03"] <-  '#e7298a'

col.pred <- rownames(rda_env_mems_uncor$CCA$v) # pull the SNP names

for (i in 1:length(sel)) {           # color code candidate SNPs
  foo <- match(sel[i],col.pred)
  col.pred[foo] <- env[i]
}

col.pred[grep("scaffold",col.pred)] <- '#f1eef6' # non-candidate SNPs
col.pred[!grepl("^#", col.pred)] <- "#f1eef6"

col.pred[!col.pred %in% env] <- "gray80"
empty <- col.pred
empty.outline <- ifelse(empty %in% c("gray80"), "gray50", "black")

empty.outline <- ifelse(empty == "#00FF0000", "#00FF0000", "gray32")

bg <- c('#1b9e77','#d95f02',"purple4",'#e7298a')


plot(rda_env_mems_uncor, type="n", scaling=3, xlim=c(-1,1), ylim=c(-1,1))
#points(cawa2.rda, display="species", pch=21, cex=1, col="gray32", bg=col.pred, scaling=3)
points(rda_env_mems_uncor, display="species", pch=21, cex=1, col=empty.outline, bg=empty, scaling=3)
text(rda_env_mems_uncor, scaling=3, display="bp", col="#0868ac", cex=1)
legend("bottomright", legend=c("bio02","bio05","bio07","bio03"), 
    bty="n", col="gray32", pch=21, cex=1, pt.bg=bg)
```

# DOING ALL OF THIS ON THE CLUSTER
So, because I can't run the above stuff on all 1.whatever million SNPs on my local computer, I've got to convert all this into R scripts that can be run on my cluster. I wrote up the 03.2.RDA_cluster.R to run on the cluster. Here I'll just feed in some results to see what we're working with.

```{bash}
rsync -avzP ericacnr@colostate.edu@login.rc.colorado.edu:/scratch/alpine/ericacnr@colostate.edu/BANS/03.GEA/results /Users/ericarobertson/Desktop/BANS_adaptive_units/analysis/03.GEA/results/
```




